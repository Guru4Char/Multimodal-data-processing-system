{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBvVoQf/Yw8qt8Er/Crv5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guru4Char/Multimodal-data-processing-system/blob/main/Multimodal_data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP 1 — Install needed libraries\n",
        "# ============================================\n",
        "!pip install google-generativeai PyMuPDF python-docx python-pptx markdown\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzqhdGAcBCEr",
        "outputId": "2fb25a7b-fc3f-4b73-dae4-5b415862a33f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.12/dist-packages (1.26.5)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (3.9)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.26.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.184.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (11.3.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (3.2.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP 2 — Import libraries\n",
        "# ============================================\n",
        "import google.generativeai as genai\n",
        "import fitz  # PyMuPDF for PDF\n",
        "from docx import Document\n",
        "from pptx import Presentation\n",
        "import markdown\n",
        "from google.colab import files\n",
        "import io\n"
      ],
      "metadata": {
        "id": "gTz8svieBHwL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP 3 — Upload a file\n",
        "# ============================================\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"\\nFile uploaded: {filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "nNhHQz66BMHu",
        "outputId": "f98fa6c4-71d3-46fc-9a00-6c0bbe387ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c1f9ec08-2df9-4d0c-9fc5-240a7aa4bb78\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c1f9ec08-2df9-4d0c-9fc5-240a7aa4bb78\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Little Red Riding Hood.pdf to Little Red Riding Hood.pdf\n",
            "\n",
            "File uploaded: Little Red Riding Hood.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP 4 — Extract text depending on file type\n",
        "# ============================================\n",
        "def extract_text_from_pdf(path):\n",
        "    text = \"\"\n",
        "    with fitz.open(path) as pdf:\n",
        "        for page in pdf:\n",
        "            text += page.get_text(\"text\")\n",
        "    return text\n",
        "\n",
        "def extract_text_from_docx(path):\n",
        "    doc = Document(path)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs])\n",
        "\n",
        "def extract_text_from_pptx(path):\n",
        "    prs = Presentation(path)\n",
        "    text_runs = []\n",
        "    for slide in prs.slides:\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\"):\n",
        "                text_runs.append(shape.text)\n",
        "    return \"\\n\".join(text_runs)\n",
        "\n",
        "def extract_text_from_md(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        md_text = f.read()\n",
        "    html = markdown.markdown(md_text)\n",
        "    return html\n",
        "\n",
        "def extract_text_from_txt(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()\n",
        "\n",
        "# detect type and extract\n",
        "if filename.endswith(\".pdf\"):\n",
        "    knowledge_base = extract_text_from_pdf(filename)\n",
        "elif filename.endswith(\".docx\"):\n",
        "    knowledge_base = extract_text_from_docx(filename)\n",
        "elif filename.endswith(\".pptx\"):\n",
        "    knowledge_base = extract_text_from_pptx(filename)\n",
        "elif filename.endswith(\".md\"):\n",
        "    knowledge_base = extract_text_from_md(filename)\n",
        "elif filename.endswith(\".txt\"):\n",
        "    knowledge_base = extract_text_from_txt(filename)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported file type. Please upload pdf, docx, pptx, md, or txt.\")\n",
        "\n",
        "print(\"\\n✅ Text extraction complete. Preview (first 10000 chars):\\n\")\n",
        "print(knowledge_base[:10000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg75VxT0Ct2J",
        "outputId": "3842c31b-295b-480f-843a-e8512774ab76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Text extraction complete. Preview (first 10000 chars):\n",
            "\n",
            "Little Red Riding Hood (Simple English Story) \n",
            "  \n",
            "Once upon a time, there was a little girl called Little Red Riding Hood. She wore a red cloak, so \n",
            "everyone called her by that name. \n",
            "One day, her mother said, “Please take this basket of food to Grandma. She is sick.” Little Red Riding \n",
            "Hood said, “Okay, Mommy.” \n",
            "Her mother said, “Don’t talk to strangers, and stay on the path.” \n",
            "Little Red Riding Hood walked through the forest. On the way, a big bad wolf saw her. He wanted to \n",
            "eat her but smiled and asked, “Where are you going, little girl?” \n",
            "She said, “I’m going to see my grandma. She is sick.” \n",
            "The wolf thought, “I will eat the grandmother first and then the girl.” \n",
            "He ran fast to Grandma’s house. He knocked on the door. “Who is it?” asked Grandma. \n",
            "“It’s me, Little Red Riding Hood,” said the wolf in a soft voice. \n",
            "Grandma said, “Come in.” The wolf jumped in and swallowed Grandma whole! Then he put on \n",
            "Grandma’s clothes and lay in her bed. \n",
            "Little Red Riding Hood arrived and saw her “grandmother.” She said, “Grandma, what big eyes you \n",
            "have!” \n",
            "The wolf said, “All the better to see you with.” \n",
            "“Grandma, what big ears you have!” \n",
            "“All the better to hear you with.” \n",
            "“Grandma, what big teeth you have!” \n",
            "“All the better to eat you with!” said the wolf, and he jumped out of bed. \n",
            "Little Red Riding Hood screamed. A woodcutter nearby heard her. He ran in and hit the wolf. The wolf \n",
            "opened his mouth and out came Grandma! \n",
            "The wolf ran away, and Grandma and Little Red Riding Hood hugged each other. \n",
            "From that day, Little Red Riding Hood always listened to her mother. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 — Install the official Google GenAI SDK (recommended)\n",
        "!pip install -q google-genai\n"
      ],
      "metadata": {
        "id": "28q8IIxs3rn4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 — Fixed version for Google Colab\n",
        "from google import genai\n",
        "import getpass\n",
        "\n",
        "# Ask for your API key (you get this from Google AI Studio)\n",
        "API_KEY = getpass.getpass(\"Paste your Gemini / Google AI Studio API key here: \")\n",
        "\n",
        "# ✅ Create the client with the API key directly\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "print(\"Google GenAI client successfully configured! ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10_PxSnZ3tR1",
        "outputId": "866e7bfd-b31a-44b2-db83-8c9f81c27ea6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your Gemini / Google AI Studio API key here: ··········\n",
            "Google GenAI client successfully configured! ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 — (Optional) Try listing available models in your account (if supported)\n",
        "# NOTE: listing may not be supported in all SDK versions/accounts; if not, skip.\n",
        "try:\n",
        "    models = client.models.list()  # may return a list or raise if not allowed\n",
        "    print(\"Available models (first 20 shown):\")\n",
        "    for m in models[:20]:\n",
        "        print(\"-\", m.get(\"name\") or m.get(\"id\") or m)\n",
        "except Exception as e:\n",
        "    print(\"Listing models is not supported or failed (that's ok). Error message:\")\n",
        "    print(e)\n",
        "    print(\"\\nYou can use a known supported model name such as 'gemini-2.5-flash' or 'gemini-1.5-pro' depending on your access. See docs: https://ai.google.dev/gemini-api/docs/quickstart\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYRM6roa3tOe",
        "outputId": "84466413-4de3-4d8b-c0cd-cb300aae885f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available models (first 20 shown):\n",
            "Listing models is not supported or failed (that's ok). Error message:\n",
            "'Model' object has no attribute 'get'\n",
            "\n",
            "You can use a known supported model name such as 'gemini-2.5-flash' or 'gemini-1.5-pro' depending on your access. See docs: https://ai.google.dev/gemini-api/docs/quickstart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 — Simple local search fallback (no API required)\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def simple_local_search(document_text, question, top_k=5):\n",
        "    # split into sentences (naive)\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', document_text.strip())\n",
        "    # tokenise question\n",
        "    qtokens = re.findall(r'\\w+', question.lower())\n",
        "    # score sentences by token overlap\n",
        "    scores = []\n",
        "    for s in sentences:\n",
        "        stokens = re.findall(r'\\w+', s.lower())\n",
        "        common = set(qtokens) & set(stokens)\n",
        "        scores.append((len(common), s))\n",
        "    # sort by score\n",
        "    scores.sort(key=lambda x: x[0], reverse=True)\n",
        "    top = [s for score,s in scores if score>0][:top_k]\n",
        "    if not top:\n",
        "        return \"No strong match found in the document (try rephrasing the question).\"\n",
        "    return \"\\n\\n\".join(top)\n",
        "\n",
        "# Interactive loop using fallback\n",
        "print(\"Using fallback local search. Type 'exit' to quit.\\n\")\n",
        "while True:\n",
        "    q = input(\"Your question: \")\n",
        "    if q.strip().lower() == \"exit\":\n",
        "        print(\"Session ended. 👋\")\n",
        "        break\n",
        "    print(\"\\nAnswer (from local search):\\n\")\n",
        "    print(simple_local_search(knowledge_base, q))\n",
        "    print(\"\\n\" + \"-\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGBrSdI43tKi",
        "outputId": "405eef72-66e4-4bed-fcf0-62e5af60a623"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using fallback local search. Type 'exit' to quit.\n",
            "\n",
            "Your question: what is wolf name?\n",
            "\n",
            "Answer (from local search):\n",
            "\n",
            "She is sick.” \n",
            "The wolf thought, “I will eat the grandmother first and then the girl.” \n",
            "He ran fast to Grandma’s house.\n",
            "\n",
            "Little Red Riding Hood arrived and saw her “grandmother.” She said, “Grandma, what big eyes you \n",
            "have!” \n",
            "The wolf said, “All the better to see you with.” \n",
            "“Grandma, what big ears you have!” \n",
            "“All the better to hear you with.” \n",
            "“Grandma, what big teeth you have!” \n",
            "“All the better to eat you with!” said the wolf, and he jumped out of bed.\n",
            "\n",
            "She wore a red cloak, so \n",
            "everyone called her by that name.\n",
            "\n",
            "She is sick.” Little Red Riding \n",
            "Hood said, “Okay, Mommy.” \n",
            "Her mother said, “Don’t talk to strangers, and stay on the path.” \n",
            "Little Red Riding Hood walked through the forest.\n",
            "\n",
            "On the way, a big bad wolf saw her.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Your question: what is 5th line in the passage\n",
            "\n",
            "Answer (from local search):\n",
            "\n",
            "She is sick.” Little Red Riding \n",
            "Hood said, “Okay, Mommy.” \n",
            "Her mother said, “Don’t talk to strangers, and stay on the path.” \n",
            "Little Red Riding Hood walked through the forest.\n",
            "\n",
            "She is sick.” \n",
            "The wolf thought, “I will eat the grandmother first and then the girl.” \n",
            "He ran fast to Grandma’s house.\n",
            "\n",
            "“It’s me, Little Red Riding Hood,” said the wolf in a soft voice.\n",
            "\n",
            "Grandma said, “Come in.” The wolf jumped in and swallowed Grandma whole!\n",
            "\n",
            "Little Red Riding Hood arrived and saw her “grandmother.” She said, “Grandma, what big eyes you \n",
            "have!” \n",
            "The wolf said, “All the better to see you with.” \n",
            "“Grandma, what big ears you have!” \n",
            "“All the better to hear you with.” \n",
            "“Grandma, what big teeth you have!” \n",
            "“All the better to eat you with!” said the wolf, and he jumped out of bed.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Your question: exit\n",
            "Session ended. 👋\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YX-h5Pjm3tIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VbTy61Jj3tGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2G9abKNw3tDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "68vPhtLh3tBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zPSbxpWw3s_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JsRaVis03s8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ukJUmzll3s5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ht43_7vW3suD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tr3qa0dF3sVE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}